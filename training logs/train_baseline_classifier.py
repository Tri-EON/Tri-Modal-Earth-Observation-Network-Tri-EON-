# -*- coding: utf-8 -*-
"""train_baseline_classifier.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12MTytuRiuGnXr6KG5v9gnCxjhoFIuMfL
"""

!pip install torch torchvision transformers albumentations tqdm
from zipfile import ZipFile
ZipFile("cleaned_data.zip").extractall("cleaned_data")

import torch
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
from PIL import Image
import os
from tqdm import tqdm
import numpy as np

class EuroSATDataset(Dataset):
    def __init__(self, root_dir, transform=None):
        self.root_dir = root_dir
        self.classes = sorted(os.listdir(root_dir))
        self.samples = []
        for label, class_name in enumerate(self.classes):
            class_dir = os.path.join(root_dir, class_name)
            for img_file in os.listdir(class_dir):
                self.samples.append((os.path.join(class_dir, img_file), label))
        self.transform = transform

    def __len__(self):
        return len(self.samples)

    def __getitem__(self, idx):
        img_path, label = self.samples[idx]
        image = Image.open(img_path).convert("RGB")
        if self.transform:
            image = self.transform(image)
        return image, label
transform = transforms.Compose([
    transforms.Resize((128,128)),
    transforms.ToTensor(),
    transforms.Normalize([0.5]*3, [0.5]*3)
])

train_ds = EuroSATDataset("cleaned_data/train", transform)
val_ds   = EuroSATDataset("cleaned_data/val", transform)
test_ds  = EuroSATDataset("cleaned_data/test", transform)

train_loader = DataLoader(train_ds, batch_size=16, shuffle=True)
val_loader   = DataLoader(val_ds, batch_size=16)
test_loader  = DataLoader(test_ds, batch_size=16)

from transformers import SegformerForImageClassification, SegformerImageProcessor

num_classes = len(train_ds.classes)

model = SegformerForImageClassification.from_pretrained(
    "nvidia/segformer-b0-finetuned-ade-512-512",
    num_labels=num_classes
)

processor = SegformerImageProcessor.from_pretrained("nvidia/segformer-b0-finetuned-ade-512-512")

print("Train samples:", len(train_ds))
print("Val samples:", len(val_ds))
print("Test samples:", len(test_ds))

# Peek at one batch to confirm shape
for imgs, labels in train_loader:
    print("Batch shape:", imgs.shape)
    print("Labels:", labels[:5])
    break

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)

optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)
criterion = torch.nn.CrossEntropyLoss()

import torch
import torch.nn as nn
import torch.optim as optim
import time
from tqdm.notebook import tqdm

def train_model(model, train_loader, val_loader, epochs=3, patience=2, device='cuda'):
    model = model.to(device)
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=1e-4)

    best_val_loss = float('inf')
    patience_counter = 0

    for epoch in range(epochs):
        start_time = time.time()
        print(f"Epoch [{epoch+1}/{epochs}]")

        # training
        model.train()
        running_loss = 0.0

        for batch_idx, (images, labels) in enumerate(tqdm(train_loader, desc="Training")):
            images, labels = images.to(device), labels.to(device)
            optimizer.zero_grad()

            outputs = model(images).logits
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

            running_loss += loss.item()

            if (batch_idx + 1) % 50 == 0:
                print(f"  Batch {batch_idx+1}/{len(train_loader)} - Loss: {loss.item():.4f}")

        avg_train_loss = running_loss / len(train_loader)
        print(f"Average Training Loss: {avg_train_loss:.4f}")

        # validation
        model.eval()
        val_loss = 0.0
        correct = 0
        total = 0
        with torch.no_grad():
            for images, labels in val_loader:
                images, labels = images.to(device), labels.to(device)
                outputs = model(images).logits
                loss = criterion(outputs, labels)
                val_loss += loss.item()
                _, preds = torch.max(outputs, 1)
                correct += (preds == labels).sum().item()
                total += labels.size(0)

        avg_val_loss = val_loss / len(val_loader)
        val_acc = correct / total
        print(f"Validation Loss: {avg_val_loss:.4f} | Accuracy: {val_acc:.4f}")

        # early stopping
        if avg_val_loss < best_val_loss:
            best_val_loss = avg_val_loss
            patience_counter = 0
            torch.save(model.state_dict(), "best_model.pth")
            print("Model saved (new best validation loss).")
        else:
            patience_counter += 1
            print(f" No improvement. Patience counter: {patience_counter}/{patience}")
            if patience_counter >= patience:
                print("‚èπ Early stopping triggered.")
                break

        end_time = time.time()
        epoch_time = end_time - start_time
        print(f"Epoch Time: {epoch_time:.2f}s ({epoch_time/60:.2f} min)")

    print("\n Training complete! Best model saved as 'best_model.pth'")

train_model(model, train_loader, val_loader, epochs=25, patience=4)

import torch

model.load_state_dict(torch.load("best_model.pth", map_location='cuda'))
model.eval()
print(" Model loaded for evaluation!")

from sklearn.metrics import classification_report, confusion_matrix
import numpy as np

criterion = torch.nn.CrossEntropyLoss()
model.eval()

test_loss = 0.0
correct = 0
total = 0
all_preds, all_labels = [], []

with torch.no_grad():
    for images, labels in test_loader:
        images, labels = images.to('cuda'), labels.to('cuda')
        outputs = model(images).logits
        loss = criterion(outputs, labels)
        test_loss += loss.item()

        _, preds = torch.max(outputs, 1)
        correct += (preds == labels).sum().item()
        total += labels.size(0)

        all_preds.extend(preds.cpu().numpy())
        all_labels.extend(labels.cpu().numpy())

avg_test_loss = test_loss / len(test_loader)
test_acc = correct / total

print(f" Test Loss: {avg_test_loss:.4f}")
print(f" Test Accuracy: {test_acc*100:.2f}%")

# Classification Report
print("\nDetailed Classification Report:")
# EuroSAT class names
class_names = [
    'AnnualCrop', 'Forest', 'HerbaceousVegetation', 'Highway',
    'Industrial', 'Pasture', 'PermanentCrop', 'Residential',
    'River', 'SeaLake'
]

print(classification_report(all_labels, all_preds, target_names=class_names))

import torch
import matplotlib.pyplot as plt
import random
import seaborn as sns
import numpy as np
from sklearn.metrics import confusion_matrix, classification_report

class_names = [
    'AnnualCrop', 'Forest', 'HerbaceousVegetation', 'Highway',
    'Industrial', 'Pasture', 'PermanentCrop', 'Residential',
    'River', 'SeaLake'
]

# Evaluate and Gather Predictions
model.eval()
all_labels = []
all_preds = []
all_probs = []

with torch.no_grad():
    for imgs, labels in test_loader:
        imgs, labels = imgs.to('cuda'), labels.to('cuda')

        # For Hugging Face models, extract .logits
        outputs = model(imgs)
        if hasattr(outputs, "logits"):
            outputs = outputs.logits

        probs = torch.softmax(outputs, dim=1)
        preds = torch.argmax(probs, dim=1)

        all_labels.extend(labels.cpu().numpy())
        all_preds.extend(preds.cpu().numpy())
        all_probs.extend(probs.cpu().numpy())

# Classification Report
print("\n Detailed Classification Report:\n")
print(classification_report(all_labels, all_preds, target_names=class_names))

# Confusion Matrix
cm = confusion_matrix(all_labels, all_preds)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues",
            xticklabels=class_names, yticklabels=class_names)
plt.xlabel("Predicted")
plt.ylabel("True")
plt.title("Confusion Matrix - EuroSAT Test Set")
plt.tight_layout()
plt.savefig("confusion_matrix.png", dpi=300, bbox_inches="tight")
plt.show()

# Random Sample Predictions Visualization
print("\n Visualizing Random Predictions...")
indices = random.sample(range(len(test_ds)), 5)

plt.figure(figsize=(15, 6))
for i, idx in enumerate(indices):
    img, label = test_ds[idx]
    with torch.no_grad():
        output = model(img.unsqueeze(0).to('cuda'))
        if hasattr(output, "logits"):
            output = output.logits
        pred_class = torch.argmax(output, dim=1).item()

    # Normalize for visualization
    img_np = img.permute(1, 2, 0).cpu().numpy()
    img_np = (img_np - img_np.min()) / (img_np.max() - img_np.min() + 1e-5)

    plt.subplot(1, 5, i + 1)
    plt.imshow(img_np)
    plt.title(f"GT: {class_names[label]}\nPred: {class_names[pred_class]}")
    plt.axis('off')

plt.suptitle("Sample Predictions on EuroSAT Test Set", fontsize=14)
plt.tight_layout()
plt.savefig('sample_predictions_fixed.png', dpi=300, bbox_inches='tight')
plt.show()

import os
import shutil

os.makedirs("model_results", exist_ok=True)

if os.path.exists("best_model.pth"):
    shutil.copy("best_model.pth", "model_results/best_model.pth")

if os.path.exists("confusion_matrix.png"):
    shutil.copy("confusion_matrix.png", "model_results/confusion_matrix.png")

if os.path.exists("sample_predictions_fixed.png"):
    shutil.copy("sample_predictions_fixed.png", "model_results/sample_predictions_fixed.png")


shutil.make_archive("model_results", 'zip', "model_results")
from google.colab import files
files.download("model_results.zip")