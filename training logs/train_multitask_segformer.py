# -*- coding: utf-8 -*-
"""train_multitask_segformer.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CF3CBEfSA-liBw0sbjiQeDWSmo1mtRHl
"""

import os, zipfile, torch, torch.nn as nn
from torch.utils.data import DataLoader
from torchvision import transforms, datasets
from transformers import SegformerModel

if os.path.exists("cleaned_data.zip"):
    with zipfile.ZipFile("cleaned_data.zip", "r") as zip_ref:
        zip_ref.extractall("cleaned_data")
    print("cleaned_data extracted successfully!")
else:
    print("cleaned_data.zip not found!")

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("Device:", device)

# Multi-Task SegFormer Model
class SegFormerMultiTaskModel(nn.Module):
    def __init__(self, num_classes=10, seg_classes=10):
        super().__init__()
        # Load pretrained SegFormer encoder
        self.segformer = SegformerModel.from_pretrained(
            "nvidia/segformer-b0-finetuned-ade-512-512"
        )
        hidden_dim = self.segformer.config.hidden_sizes[-1]  # usually 256

        # Classification head
        self.classifier = nn.Linear(hidden_dim, num_classes)

        # Segmentation head
        self.segmentation_head = nn.Sequential(
            nn.Conv2d(hidden_dim, seg_classes, kernel_size=1),
            nn.Upsample(scale_factor=4, mode="bilinear", align_corners=False),
        )

        # Optional Change Detection head
        self.change_head = nn.Sequential(
            nn.Conv2d(hidden_dim * 2, 1, kernel_size=3, padding=1),
            nn.Sigmoid(),
        )

    def forward(self, x, x2=None):
        out1 = self.segformer(x)
        feats1 = out1.last_hidden_state  # [B, H*W, C] or [B, C, H, W]

        # üîß Handle both shapes automatically
        if feats1.dim() == 3:
            B, HW, C = feats1.shape
            H = W = int(HW ** 0.5)
            feats1_reshaped = feats1.permute(0, 2, 1).reshape(B, C, H, W)
        elif feats1.dim() == 4:
            feats1_reshaped = feats1
            B, C, H, W = feats1_reshaped.shape
        else:
            raise ValueError(f"Unexpected feature shape: {feats1.shape}")

        # üîπ Classification
        pooled = feats1_reshaped.mean(dim=[2, 3])
        cls_logits = self.classifier(pooled)

        # üîπ Segmentation
        seg_out = self.segmentation_head(feats1_reshaped)

        # üîπ Change Detection (optional, if second image given)
        change_out = None
        if x2 is not None:
            out2 = self.segformer(x2)
            feats2 = out2.last_hidden_state
            if feats2.dim() == 3:
                feats2 = feats2.permute(0, 2, 1).reshape(B, C, H, W)
            diff = torch.abs(feats1_reshaped - feats2)
            change_out = self.change_head(torch.cat([feats1_reshaped, diff], dim=1))

        return cls_logits, seg_out, change_out

# Load Pretrained Encoder Weights
model = SegFormerMultiTaskModel(num_classes=10, seg_classes=10)
best_model_path = "model_results/best_model.pth"

if os.path.exists(best_model_path):
    checkpoint = torch.load(best_model_path, map_location=device)
    filtered_state_dict = {k: v for k, v in checkpoint.items() if "segformer" in k}
    missing, unexpected = model.load_state_dict(filtered_state_dict, strict=False)
    print(" Encoder weights loaded successfully")
    print("Missing keys:", missing)
    print("Unexpected keys:", unexpected)
else:
    print(" best_model.pth not found!")

model.to(device)

transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
])

train_ds = datasets.ImageFolder("cleaned_data/train", transform=transform)
val_ds = datasets.ImageFolder("cleaned_data/val", transform=transform)

train_dl = DataLoader(train_ds, batch_size=8, shuffle=True)
val_dl = DataLoader(val_ds, batch_size=8, shuffle=False)
print(f" Classes found: {train_ds.classes}")

criterion_cls = nn.CrossEntropyLoss()
optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)
scaler = torch.amp.GradScaler('cuda')
num_epochs = 5

# Training Loop
for epoch in range(num_epochs):
    model.train()
    total_loss = 0
    for imgs, labels in train_dl:
        imgs, labels = imgs.to(device), labels.to(device)
        optimizer.zero_grad()
        with torch.amp.autocast('cuda'):
            cls_logits, seg_out, _ = model(imgs)
            loss = criterion_cls(cls_logits, labels)
        scaler.scale(loss).backward()
        scaler.step(optimizer)
        scaler.update()
        total_loss += loss.item()
    print(f" Epoch [{epoch+1}/{num_epochs}] - Loss: {total_loss/len(train_dl):.4f}")

model.eval()
correct, total = 0, 0
with torch.no_grad():
    for imgs, labels in val_dl:
        imgs, labels = imgs.to(device), labels.to(device)
        cls_logits, _, _ = model(imgs)
        preds = torch.argmax(cls_logits, dim=1)
        correct += (preds == labels).sum().item()
        total += labels.size(0)
val_acc = 100 * correct / total
print(f" Validation Accuracy: {val_acc:.2f}%")

os.makedirs("finetuned_results", exist_ok=True)
torch.save(model.state_dict(), "finetuned_results/segformer_multitask_finetuned.pth")
print(" Model saved at finetuned_results/segformer_multitask_finetuned.pth")

# test phase
import torch
from torchvision import datasets, transforms
from torch.utils.data import DataLoader

# load test dataset
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
])
test_ds = datasets.ImageFolder("cleaned_data/test", transform=transform)
test_dl = DataLoader(test_ds, batch_size=8, shuffle=False)
print(f"Test Classes: {test_ds.classes}")

# reload the fine-tuned model
model_path = "finetuned_results/segformer_multitask_finetuned.pth"
model = SegFormerMultiTaskModel(num_classes=10, seg_classes=10)
state_dict = torch.load(model_path, map_location=device)
model.load_state_dict(state_dict, strict=False)
model.to(device)
model.eval()
print("Model loaded for testing!")

# evaluate on test set
correct, total = 0, 0
with torch.no_grad():
    for imgs, labels in test_dl:
        imgs, labels = imgs.to(device), labels.to(device)
        cls_logits, _, _ = model(imgs)
        preds = torch.argmax(cls_logits, dim=1)
        correct += (preds == labels).sum().item()
        total += labels.size(0)

test_acc = 100 * correct / total
print(f"Final Test Accuracy: {test_acc:.2f}%")

# MULTI-TASK MODEL VERIFICATION

import matplotlib.pyplot as plt
from torchvision.utils import make_grid
import numpy as np
from PIL import Image

# Reload your fine-tuned model
model_path = "finetuned_results/segformer_multitask_finetuned.pth"
model = SegFormerMultiTaskModel(num_classes=10, seg_classes=10)
state_dict = torch.load(model_path, map_location=device)
model.load_state_dict(state_dict, strict=False)
model.to(device)
model.eval()
print("Loaded fine-tuned multitask model")

# Get one mini-batch of test images
test_ds = datasets.ImageFolder("cleaned_data/test", transform=transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor()
]))
test_dl = DataLoader(test_ds, batch_size=4, shuffle=True)
imgs, labels = next(iter(test_dl))
imgs, labels = imgs.to(device), labels.to(device)

# Run through model (classification + segmentation)
with torch.no_grad():
    cls_logits, seg_out, _ = model(imgs)

# Classification predictions
preds = torch.argmax(cls_logits, dim=1)
print("\n Classification Results:")
for i in range(len(preds)):
    print(f"Image {i+1}: Predicted = {test_ds.classes[preds[i]]}, True = {test_ds.classes[labels[i]]}")

# Visualize segmentation output
seg_out = torch.argmax(seg_out, dim=1).cpu().numpy()
imgs_np = imgs.cpu().permute(0, 2, 3, 1).numpy()

plt.figure(figsize=(12, 8))
for i in range(len(imgs_np)):
    plt.subplot(2, len(imgs_np), i + 1)
    plt.imshow(imgs_np[i])
    plt.title(f"Input ({test_ds.classes[labels[i]]})")
    plt.axis("off")

    plt.subplot(2, len(imgs_np), len(imgs_np) + i + 1)
    plt.imshow(seg_out[i], cmap="viridis")
    plt.title(f"Segmentation")
    plt.axis("off")

plt.tight_layout()
plt.show()

# Try Change Detection
# Pick two random images and see if the model returns a difference map
img1, _ = test_ds[0]
img2, _ = test_ds[10]
img1, img2 = img1.unsqueeze(0).to(device), img2.unsqueeze(0).to(device)

with torch.no_grad():
    _, _, change_map = model(img1, img2)

plt.figure(figsize=(10, 4))
plt.subplot(1, 3, 1); plt.imshow(img1.squeeze().permute(1,2,0).cpu()); plt.title("t‚ÇÅ")
plt.subplot(1, 3, 2); plt.imshow(img2.squeeze().permute(1,2,0).cpu()); plt.title("t‚ÇÇ")
plt.subplot(1, 3, 3); plt.imshow(change_map.squeeze().cpu(), cmap="hot"); plt.title("Detected Change")
plt.show()

import torch, os
import matplotlib.pyplot as plt
from torchvision import datasets, transforms
from transformers import SegformerModel
import numpy as np

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

class SegFormerMultiTaskModel(torch.nn.Module):
    def __init__(self, num_classes=10, seg_classes=10):
        super().__init__()
        self.segformer = SegformerModel.from_pretrained(
            "nvidia/segformer-b0-finetuned-ade-512-512"
        )
        hidden_dim = self.segformer.config.hidden_sizes[-1]

        # Same heads as in training
        self.classifier = torch.nn.Linear(hidden_dim, num_classes)
        self.segmentation_head = torch.nn.Sequential(
            torch.nn.Conv2d(hidden_dim, seg_classes, kernel_size=1),
            torch.nn.Upsample(scale_factor=4, mode="bilinear", align_corners=False)
        )
        self.change_head = torch.nn.Sequential(
            torch.nn.Conv2d(hidden_dim * 2, 1, kernel_size=3, padding=1),
            torch.nn.Sigmoid()
        )

    def forward(self, x, x2=None):
        out1 = self.segformer(x)
        feats1 = out1.last_hidden_state
        if feats1.dim() == 3:
            B, HW, C = feats1.shape
            H = W = int(HW ** 0.5)
            feats1 = feats1.permute(0, 2, 1).reshape(B, C, H, W)
        pooled = feats1.mean(dim=[2, 3])
        cls_logits = self.classifier(pooled)
        seg_out = self.segmentation_head(feats1)

        change_out = None
        if x2 is not None:
            out2 = self.segformer(x2)
            feats2 = out2.last_hidden_state
            if feats2.dim() == 3:
                feats2 = feats2.permute(0, 2, 1).reshape(B, C, H, W)
            diff = torch.abs(feats1 - feats2)
            change_out = self.change_head(torch.cat([feats1, diff], dim=1))
        return cls_logits, seg_out, change_out

# Load model exactly as trained
model = SegFormerMultiTaskModel(num_classes=10, seg_classes=10).to(device)
state_dict = torch.load("finetuned_results/segformer_multitask_finetuned.pth", map_location=device)
missing, unexpected = model.load_state_dict(state_dict, strict=False)
print("Model loaded successfully")
print("Missing keys:", missing)
print("Unexpected keys:", unexpected)

model.eval()

# Load test dataset
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
])
test_ds = datasets.ImageFolder("cleaned_data/test", transform=transform)
test_dl = torch.utils.data.DataLoader(test_ds, batch_size=4, shuffle=False)
classes = test_ds.classes
os.makedirs("visual_results", exist_ok=True)

# Visualize predictions
with torch.no_grad():
    imgs, labels = next(iter(test_dl))
    imgs, labels = imgs.to(device), labels.to(device)
    cls_logits, seg_out, _ = model(imgs)
    preds = torch.argmax(cls_logits, dim=1)
    seg_preds = torch.argmax(seg_out, dim=1).cpu()

    for i in range(len(imgs)):
        fig, ax = plt.subplots(1, 2, figsize=(7, 4))
        ax[0].imshow(imgs[i].permute(1, 2, 0).cpu())
        ax[0].set_title(f"Input: {classes[labels[i]]}\nPred: {classes[preds[i]]}")
        ax[0].axis("off")

        ax[1].imshow(seg_preds[i])
        ax[1].set_title("Predicted Segmentation")
        ax[1].axis("off")

        plt.tight_layout()
        plt.savefig(f"visual_results/result_{i}.png")
        plt.close()

print("Visualization images saved in visual_results/")

import os, zipfile

output_zip = "multitask_finetuned_and_visuals.zip"

if os.path.exists(output_zip):
    os.remove(output_zip)

with zipfile.ZipFile(output_zip, 'w') as zipf:
    for folder in ['finetuned_results', 'visual_results']:
        if os.path.exists(folder):
            for root, _, files in os.walk(folder):
                for file in files:
                    file_path = os.path.join(root, file)
                    zipf.write(file_path)
print(f"Zipped successfully ‚Üí {output_zip}")

from google.colab import files
files.download("multitask_finetuned_and_visuals.zip")

